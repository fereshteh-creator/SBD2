---
title: "Digitec Analysis"
format:
  html:
    df-print: kable
    toc: true
    code-tools: true

editor: visual
author: Fereshteh, Anna, Sen, Colin Marti (pls add your full name)
---

## 1. Business Plan Analysis

Digitec Galaxus is Switzerland’s largest online retailer for consumer electronics, operating exclusively via e-commerce. Despite nationwide reach, customer behavior likely differs across cantons due to income, urbanization, age, citizenship, and household structures.

This project explores how these demographic and regional factors influence online purchases using: - \~163,000 Digitec transaction records, and - Canton-level demographic data from the Swiss Federal Statistical Office (BFS).

The findings will guide a data-driven marketing strategy to personalize digital campaigns and increase online sales efficiency.

### 1.1. Business Problem

> **How can regional demographics be used to improve Digitec’s online marketing strategy and boost conversions across Switzerland?**

Digitec currently uses uniform national marketing, but demographic diversity suggests that: - Urban cantons might favor high-end tech, - Rural areas could prefer affordable products, - Younger, single populations may show distinct category interests.

By linking demographic patterns with online purchasing data, Digitec can **target audiences more intelligently** and tailor its digital campaigns for maximum impact.

### 1.2. Data Overview

| Source | Description | Key Variables |
|:-----------------------|:-----------------------|:-----------------------|
| **Digitec Transactions (`DigitecLive_Final.csv`)** | \~163k web-scraped online transactions from Digitec’s live purchase feed | `brandName`, `infos.Category`, `salesPrice.amountIncl`, `dateTime`, `mun_canton` |
| **BFS Population Data (`population_2023.xlsx`)** | Canton-level demographics (2023) | `Total`, `Swiss`, `Foreigner`, `Urban`, `Intermediate`, `Rural`, `Age_0_19`, `Age_20_64`, `Age_65plus`, `Single`, `Married`, `Widowed`, `Divorced` |
| **BFS Population by Age (`mns_population-by-age-2023.xlsx`)** | Detailed population structure by age and region | `Region`, `Total`, `Age_0_4`, `Age_5_9`, …, `Age_80plus` |
| **BFS Population by Gender (`mns-population-by-gender-2023.xlsx`)** | Gender composition by canton and municipality (2023) | `Region`, `Total_All`, `Mann_All`, `Frau_All`, `Swiss`, `Foreigner` |

These additional datasets allow the inclusion of **more granular demographic information** — enabling a refined analysis of age- and gender-related purchasing behavior across regions.

### 1.3. Unit of Analysis

The analysis is now conducted at the **municipality level** ($n \approx 2,200$), using the official **BFS municipality number (`mun_bfsnr`)** as the join key between datasets.

Each municipality represents one observation containing: - $sales\_per\_capita = \frac{total\_sales}{population}$\
- Average order value (CHF)\
- Age-group shares (e.g., % under 20, % over 65)\
- Gender composition (% male, % female)\
- Citizenship composition (% Swiss, % foreign)

This finer-grained approach allows for **more localized insights**, capturing demographic and purchasing differences that are hidden when aggregating by canton.

------------------------------------------------------------------------

### 1.4. Methodology

#### 1.4.1. Analytical Steps

1.  **Aggregate** Digitec transaction data by municipality (`mun_bfsnr`)\
    → Compute total sales, average price, and transaction count for each municipality.\
2.  **Merge** the municipality-level BFS datasets on population, gender, and age using the `mun_bfsnr` key.\
3.  **Compute derived demographic indicators:**
    -   Gender ratio: $\frac{Male}{Female}$\
    -   Share of foreign residents: $\frac{Foreigner}{Total}$\
    -   Age structure: $\frac{Population_{0-19}}{Total}$, $\frac{Population_{20-64}}{Total}$, $\frac{Population_{65+}}{Total}$\
    -   Sales per capita and average order value\
4.  **Explore correlations** between online sales indicators and demographics:
    -   Are younger or more international municipalities buying more expensive products?\
    -   Do gender or age structures explain variations in spending per capita?\
5.  **Visualize** geographic and demographic patterns using:
    -   Choropleth maps by municipality (sales per capita, average price, etc.)\
    -   Scatterplots linking demographics to sales variables\
    -   Heatmaps of demographic vs. economic indicators\
6.  **Identify four key insights** to inform Digitec’s new data-driven marketing campaign.

#### 1.4.2. Research Questions

| Demographic Dimension | Research Question | Usage Example (What Digitec Could Do) |
|:-----------------------|:-----------------------|:-----------------------|
| **Population Size** | Do larger cantons generate proportionally more online sales? | Allocate higher Google Ads and social-media budgets to densely populated cantons to maximize reach. |
| **Gender Composition** | Does male/female ratio affect product mix (e.g., gaming vs. home appliances)? | Adapt homepage banners or email content to match regional gender patterns in purchases. |
| **Citizenship** | Are foreign residents associated with higher online spending? | Run multilingual (DE/FR/EN) ads and feature global brands (Apple, Samsung) in foreigner-dense cantons. |
| **Urbanization** | Do urban cantons buy more premium electronics than rural ones? -\> How do we define premium, expensive things are not always premium for example.\* (Sen) | Promote high-end products in cities; highlight budget or refurbished offers in rural regions. |
| **Age Structure** | Which age profile correlates with online activity? -\> maybe change to something like: How do different age groups' online purchasing differ? let's find a nice way to phrase this questions (Sen)\* | Target younger regions with gaming and mobile ads; older regions with home-office and wellness tech. |
| **Marital Status** | Do single vs. married populations differ in purchase categories? | Offer “family bundles” or smart-home packages for married cantons; focus on personal devices for single-dominant areas. |

## 1.5. Strategic Impact

By merging **online sales data** with **BFS demographic indicators**, Digitec can: - Move from national-level campaigns to **regionally adaptive marketing**.\
- Align ad language, pricing, and products with **local audience characteristics**.\
- Strengthen relevance and **optimize ad spend efficiency**.

## 2. Setup and Data Loading

This first code chunk sets up the R environment by loading all necessary libraries for the analysis and loading the four primary datasets. The chunk is configured with `include: false` to hide it from the final rendered report for a cleaner presentation.

```{r setup}
#| label: setup
#| include: false 

# Load all required libraries for the project
library(tidyverse) # For data manipulation (dplyr) and visualization (ggplot2)
library(readxl)    # To read Excel files
library(lubridate) # To work with date-time values
library(stringr)   # To work with regex


# Load digitect dataset
load("digitec.RData") # Loads the 'data' object

# Save to descriptive variable
digitec_data <- get("data")

## Load BFS data sets

# Load cantonal population data 
canton_population <- read_excel("population_2023.xlsx")

# Load Municipal population data by gender
municipal_population_gender <- read_excel("mns-population-by-gender-2023.xlsx")

# Load Municipal population data by age
municipal_population_age <- read_excel("mns-population-by-age-2023.xlsx")

```

## 3. Data Cleaning and Preprocessing

This section details the systematic process of cleaning and preparing the raw data of the required data sets. The goal is to produce a reliable, aggregated dataset at the municipal and cantonal level. The municipal data will be a combination of three datasets: "mns-population-by-age", "mns-population-by-gender", and the digitec dataset. The cantonal dataset will be a merging of the BFS demographic data and the digitec dataset.

### 3.1. Digitec Dataset

An initial inspection of the raw Digitec data revealed several necessary cleaning steps:

-   **Correcting Data Types:** The `dateTime` column was stored as a character string and needed to be converted into a proper date-time format for time-based analysis.
-   **Removing Irrelevant Columns:** Many columns were redundant (e.g., price with and without VAT), contained technical metadata, or were not relevant to the analysis (e.g., image URLs).
-   **Ensuring Data Quality:** Transactions without a price or a clear, unique geographic match (`mun_nhits != 1`) were removed to ensure the reliability of the analysis.
-   **Feature Engineering:** More useful features were extracted from the raw data, such as the day of the week from the `dateTime` column or the clean product category name from a URL string.

#### 3.1.1. Data Cleaning & Engineering

The following steps were implemented in a single, coherent `dplyr` pipeline for efficiency and reproducibility. The result is a cleaned DataFrame named `data_clean`.

```{r data-cleaning-pipeline}
#| label: data-cleaning-pipeline

# Comprehensive cleaning and transformation of the raw data

digitec_data_clean <- digitec_data %>%
  
  # Select and rename relevant columns for better readability
  rename(
    price = salesPrice.amountIncl,
    category_url = infos.Category,
    sales_rank_raw = infos.Sales_Rank,
    canton = mun_canton,
    bfsnr = mun_bfsnr
  ) %>%
  select(
    price, dateTime, brandName, category_url, sales_rank_raw, canton, mun_nhits, bfsnr
  ) %>%
  
  # Filter rows to ensure data quality
  filter(
    !is.na(price),           # Keep only transactions with a price
    !is.na(canton),          # Keep only transactions with canton information
    mun_nhits == 1           # Keep only unique geographic matches
  ) %>%
  
  # Create new, useful columns (Feature Engineering)
  mutate(
    # Convert timestamp to a proper date-time format
    dateTime = ymd_hms(dateTime),
    
    # Extract useful time-based components
    hour = hour(dateTime),
    weekday = wday(dateTime, label = TRUE, week_start = 1),
    
    # Extract the product category from the URL
    category = basename(category_url)
  )

```

#### 3.1.2. Exploratory Data Analysis (EDA)

After cleaning the data, an exploratory analysis was performed on the `data_clean` set to understand fundamental patterns before aggregation.

#### Price Distribution

An analysis of product prices reveals a heavily right-skewed distribution. A large majority of transactions are for lower-priced items, while a long tail of high-value purchases contributes significantly to total revenue. The boxplot identifies these high-priced items as statistical outliers. For a marketing analysis, however, these are valid and highly valuable data points that must be retained.

```{r eda-price-plots}
#| label: eda-price-plots

# Histogram to visualize the price distribution
ggplot(digitec_data_clean, aes(x = price)) +
  geom_histogram(bins = 100, fill = "steelblue", color = "black") +
  labs(
    title = "Distribution of Product Prices",
    subtitle = "Strong right-skewed distribution with most items in the lower price range",
    x = "Price (CHF)",
    y = "Number of Transactions"
  ) +
  theme_minimal()

# Boxplot to identify outliers
ggplot(digitec_data_clean, aes(y = price)) +
  geom_boxplot(fill = "steelblue") +
  labs(
    title = "Boxplot of Product Prices",
    subtitle = "Shows a high number of high-priced products (outliers)",
    y = "Price (CHF)"
  ) +
  theme_minimal()
```

#### Top Categories and Brands

Analyzing the most frequent categories and brands provides initial insights into customer preferences. Product categories such as headphones, smartphones, and printer toner dominate sales volumes. Among brands, Apple and Samsung are clear leaders, highlighting the importance of these ecosystems to customers.

```{r eda-category-brand-plots}
#| label: eda-category-brand-plots

# Top 15 product categories by transaction count
digitec_data_clean %>%
  count(category, sort = TRUE) %>%
  top_n(15, n) %>%
  ggplot(aes(x = reorder(category, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Top 15 Product Categories",
    x = "Product Category",
    y = "Number of Transactions"
  ) +
  theme_minimal()

# Top 15 brands by transaction count
digitec_data_clean %>%
  filter(brandName != "") %>% # Exclude blank brand names
  count(brandName, sort = TRUE) %>%
  top_n(15, n) %>%
  ggplot(aes(x = reorder(brandName, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Top 15 Brands",
    x = "Brand",
    y = "Number of Transactions"
  ) +
  theme_minimal()
```

### 3.2. BFS Datasets

The data within the three BFS is mostly clean. There are no apparent missing values or errors, just some unnecessary rows. More importantly, the datasets need to be compatible for the upcoming merge with the Digitec data. \
\
The issues that we identified were as follows:

-   **Column names:** The column names of all three datasets need to be non-capitalized and follow the snake_case format in order to align with the digitec dataset.

-   **Unwanted rows:** Remove the unwanted canton and bezirk rows with the municipality datasets and rename the column to muncipality.

-   **Canton codes:** The canton names within the municipality BFS dataset are not in the standard code format.

-   **Municipality number:** The age and gender datasets have an improper municipality notation. Later on, we'll have to merge these datasets with the digitec dataset according to the municipality number, so it's imperative that we make sure they're in the same format.

-   **Ages:** Currently ages within the age datasetare not grouped in the same way as BFS' canton dataset.

#### 3.2.1 Data Cleaning & Engineering

**Municipality Level**

Firstly, we will tackle the column names; we do this simply by running each dataset through this snake_case function:

```{r}

#function which converts input to snake_case
clean_names <- function(x) {
  x %>%
    str_to_lower() %>%
    
    # Replace spaces with underscores
    str_replace_all(" ", "_")             
}

# Rename each dataset
colnames(canton_population) <- clean_names(colnames(canton_population))
colnames(municipal_population_age) <- clean_names(colnames(municipal_population_age))
colnames(municipal_population_gender) <- clean_names(colnames(municipal_population_gender))
```

Then within the age and gender datasets we can remove the unnecessary rows, rename the column and extract the bfsnr from the municipalities.

```{r row-removal}

# Rename first column to bfsnr like in the digitec dataset
colnames(municipal_population_age)[1] <- "bfsnr"
colnames(municipal_population_gender)[1] <- "bfsnr"

# Clean municipality age data
municipal_population_age_clean <- municipal_population_age %>%
  filter(str_detect(bfsnr, "^\\.+")) %>%  # Match rows starting with one or more dots
  mutate(
    bfsnr = str_extract(bfsnr, "\\d+"),  # Extract numeric code
    bfsnr = as.integer(bfsnr)
  )

# Clean municipality gender data
municipal_population_gender_clean <- municipal_population_gender %>%
  filter(str_detect(bfsnr, "^\\.+")) %>%
  mutate(
    bfsnr = str_extract(bfsnr, "\\d+"),
    bfsnr = as.integer(bfsnr)
  )

print(municipal_population_age_clean)

```

Now we group the ages from 0-19, 20-64, and 65-100+ and our age and population datasets are ready for merging.

```{r}

# Collapse into age bands
municipal_population_age_clean <- municipal_population_age_clean %>%
  rowwise() %>%
  mutate(
    `age_from_0-19` = sum(c_across(`0`:`19`), na.rm = TRUE),
    `age_from_20-64` = sum(c_across(`20`:`64`), na.rm = TRUE),
    age_from_65_and_over = sum(c_across(`65`:`99`), `100_und_mehr`, na.rm = TRUE)
  ) %>%
  ungroup() %>% select(bfsnr, total, `age_from_0-19`, `age_from_20-64`, age_from_65_and_over)

print(municipal_population_age_clean)
```

**Canton Level**

For the canton level we need to map the canton names found in the canton BFS dataset to their official abbreviations used in the transaction dataset.

```{r canton-code-mapping}
#| label: canton-code-mapping


# Define canton name-to-code mapping
canton_codes <- list(
  "Zurich" = "ZH",
  "Bern" = "BE",
  "Lucerne" = "LU",
  "Uri" = "UR",
  "Schwyz" = "SZ",
  "Obwalden" = "OW",
  "Nidwalden" = "NW",
  "Glarus" = "GL",
  "Zug" = "ZG",
  "Fribourg" = "FR",
  "Solothurn" = "SO",
  "Basel-Stadt" = "BS",
  "Basel-Landschaft" = "BL",
  "Schaffhausen" = "SH",
  "Appenzell A. Rh." = "AR",
  "Appenzell I. Rh." = "AI",
  "St. Gallen" = "SG",
  "Graubünden" = "GR",
  "Aargau" = "AG",
  "Thurgau" = "TG",
  "Ticino" = "TI",
  "Vaud" = "VD",
  "Valais" = "VS",
  "Neuchâtel" = "NE",
  "Geneva" = "GE",
  "Jura" = "JU"
)

# Convert to named vector for mapping
code_map <- setNames(unlist(canton_codes), names(canton_codes))

# Replace canton names with codes and remove non-cantons
cleaned_canton_population <- canton_population %>%
  filter(canton %in% names(canton_codes)) %>%
  mutate(canton = code_map[canton])


# Display the processed excel data
print(cleaned_canton_population)
```

### 4. Validation and Final Aggregation

#### 4.1 Digitec Dataset

An initial aggregation of the cleaned data surprisingly resulted in 29 groups instead of the 26 expected Swiss cantons. An investigation of the `canton` column revealed that the dataset also contained transactions from neighboring countries, which needed to be excluded for this analysis.

```{r validation-step}
#| label: validation-step

# A list of valid Swiss canton abbreviations
valid_swiss_cantons <- c(
  "AG", "AI", "AR", "BE", "BL", "BS", "FR", "GE", "GL", "GR", 
  "JU", "LU", "NE", "NW", "OW", "SG", "SH", "SO", "SZ", "TG", 
  "TI", "UR", "VD", "VS", "ZG", "ZH"
)

# Identify which unique codes in our data are NOT in the valid list
non_swiss_codes <- setdiff(unique(digitec_data_clean$canton), valid_swiss_cantons)

print("Found the following non-Swiss location codes:")
print(non_swiss_codes)
```

Based on this finding, the dataset was filtered to include only transactions from the 26 Swiss cantons. Afterward, the final aggregation was performed to create the analysis-ready dataset.

```{r final-aggregation}
#| label: final-aggregation

# Filter the dataset to retain only transactions from Swiss cantons
data_final_swiss <- digitec_data_clean %>%
  filter(canton %in% valid_swiss_cantons)

# Perform the final aggregation at the cantonal level
canton_data_final <- data_final_swiss %>%
  group_by(canton) %>%
  summarise(
    total_sales = sum(price, na.rm = TRUE),
    num_transactions = n(),
    avg_order_value = mean(price, na.rm = TRUE),
    top_brand = names(which.max(table(brandName))),
    top_category = names(which.max(table(category)))
  ) %>%
  arrange(desc(total_sales))
```

#### Final Aggregated Digitec Dataset

The result of this cleaning and preprocessing workflow is the `canton_data_final` DataFrame. It contains 26 rows, one for each Swiss canton, with the key performance indicators required for further analysis. This dataset is now ready to be merged with the BFS population data.

```{r display-final-table}
#| label: display-final-table
#| echo: false

# Display the final, clean table
print(canton_data_final, n = 26)
```

#### 4.1 BFS Datasets

```{r}

digitec_grouped <- digitec_data_clean %>%
  group_by(bfsnr) %>%
  summarise(
    transactions = n(),
    avg_price = mean(price, na.rm = TRUE),
    .groups = "drop"
  )
```

### 5. Data Merging 

#### 5.1. Canton Level Dataset Merge

```{r merge-canton-level-datasets}

# Merge on canton code
canton_merged_data <- left_join(canton_data_final, cleaned_canton_population, by = "canton")

# View merged dataset
print(canton_merged_data)
```

#### 5.2. Municipality Level Dataset Merge

```{r merge-municipality-level-merge}

# Merge age municipality dataset on bfsnr code
municipality_merged_data <- digitec_grouped %>%
  left_join(municipal_population_age_clean, by = "bfsnr")

# Merge gejder municipality dataset on bfsnr code
municipality_merged_data <- municipality_merged_data %>%
  left_join(municipal_population_gender_clean, by = "bfsnr")

# View merged dataset
print(municipality_merged_data)
```

## 6. Post-merge Aggregation 

To enable meaningful comparisons across cantons we add derived indicators. These indicators normalize raw counts into ratios and per-capita metrics, making them suitable for correlation analysis, segmentation, and strategic targeting.

The metrics are the following:

1.  Gender ratios
2.  Citizenship ratios
3.  Age structure
4.  Urbanization
5.  Marital status

### 6.1 Implementation in R

#### **Canton**

```{r}

 final_canton_data <- canton_merged_data %>% mutate( 
  
  # Economic indicators
  sales_per_capita = total_sales / total,
  transactions_per_capita = num_transactions / total,
  
  # Gender ratios
  share_male = male_population / total,
  share_female = female_population / total,
  
  # Citizenship ratios
  share_swiss = swiss_citizenship / total,
  share_foreign = foreigner_citizenship / total,
  
  # Age structure
  share_age_0_19 = `age_from_0-19` / total,
  share_age_20_64 = `age_from_20-64` / total,
  share_age_65_plus = age_from_65_and_over / total,
  
  # Urbanization
  share_urban = urban_commune / total,
  share_intermediate = intermediate_commune / total,
  share_rural = rural_commune / total,
  
  # Marital status
  share_single = single_status / total,
  share_married = married_status / total,
  share_widowed = widowed_status / total,
  share_divorced = divorced_status / total
)
 
# Display final merged data with computed values (note: removal of orignal values.)
print(final_canton_data)
```

#### Municipality

```{r}

final_municipality_data <- municipality_merged_data %>%
  rename(
    male_population = mann_all,
    female_population = frau_all,
    total_population = total_all,

    swiss_citizenship = total_swiss,
    foreigner_citizenship = total_foreigner
  )

final_municipality_data <- municipality_merged_data %>% mutate( 
  
  # Gender ratios
  share_male = male_population / total,
  share_female = female_population / total,
  
  # Citizenship ratios
  share_swiss = swiss_citizenship / total,
  share_foreign = foreigner_citizenship / total,
  
  # Age structure
  share_age_0_19 = `age_from_0-19` / total,
  share_age_20_64 = `age_from_20-64` / total,
  share_age_65_plus = age_from_65_and_over / total,
)
 
# Display final merged data with computed values (note: removal of orignal values.)
print(final_canton_data)
```
