---
title: "Digitec Analysis"
format:
  html:
    df-print: kable
    toc: true
    code-tools: true

editor: visual
author: Fereshteh, Anna, Sen, Colin Marti
---

## 1. Business Plan Analysis

Digitec Galaxus is Switzerland’s largest online retailer for consumer electronics, operating exclusively via e-commerce. Despite nationwide reach, customer behavior likely differs across cantons due to income, urbanization, age, citizenship, and household structures.

This project explores how these demographic and regional factors influence online purchases using: - \~163,000 Digitec transaction records, and - Canton-level demographic data from the Swiss Federal Statistical Office (BFS).

The findings will guide a data-driven marketing strategy to personalize digital campaigns and increase online sales efficiency.

### 1.1. Business Problem

> **How can regional demographics be used to improve Digitec’s online marketing strategy and boost conversions across Switzerland?**

Digitec currently uses uniform national marketing, but demographic diversity suggests that: - Urban cantons might favor high-end tech, - Rural areas could prefer affordable products, - Younger, single populations may show distinct category interests.

By linking demographic patterns with online purchasing data, Digitec can **target audiences more intelligently** and tailor its digital campaigns for maximum impact.

### 1.2. Data Overview

| Source | Description | Key Variables |
|:---------------------|:-----------------|:-------------------------------|
| **Digitec Transactions (`DigitecLive_Final.csv`)** | \~163k web-scraped online transactions | `brandName`, `infos.Category`, `salesPrice.amountIncl`, `dateTime`, `mun_canton` |
| **BFS Population Data (`population_2023.xlsx`)** | Canton-level demographics (2023) | `Total`, `Male`, `Female`, `Swiss`, `Foreigner`, `Urban`, `Intermediate`, `Rural`, `Age_0_19`, `Age_20_64`, `Age_65plus`, `Single`, `Married`, `Widowed`, `Divorced` |

### 1.3. Unit of Analysis

The analysis is performed at the canton level ($n = 26$), allowing integration of both datasets and ensuring consistent comparisons.

Each canton will serve as one observation with the following computed indicators: - $sales\_per\_capita = \frac{total\_sales}{population}$ - Average order value (CHF) - Shares of gender, citizenship, age, urbanization, and marital status

This approach balances detail with interpretability and enables clear visual communication.

## 2. Setup and Data Loading

This first code chunk sets up the R environment by loading all necessary libraries for the analysis and loading the two primary datasets. The chunk is configured with `include: false` to hide it from the final rendered report for a cleaner presentation.

```{r setup}
#| label: setup
#| include: false 

# Load all required libraries for the project
library(tidyverse) # For data manipulation (dplyr) and visualization (ggplot2)
library(readxl)    # To read Excel files
library(lubridate) # To work with date-time values

# Load the datasets
load("digitec.RData") # Loads the 'data' object
population <- read_excel("population_2023.xlsx")
```

## 3. Data Cleaning and Preprocessing

This section details the systematic process of cleaning and preparing the raw transaction data. The goal is to produce a reliable, aggregated dataset at the cantonal level, which will serve as the foundation for the subsequent merge with the BFS demographic data.

### 3.1. Cleaning Strategy

An initial inspection of the raw data revealed several necessary cleaning steps:

-   **Correcting Data Types:** The `dateTime` column was stored as a character string and needed to be converted into a proper date-time format for time-based analysis.
-   **Removing Irrelevant Columns:** Many columns were redundant (e.g., price with and without VAT), contained technical metadata, or were not relevant to the analysis (e.g., image URLs).
-   **Ensuring Data Quality:** Transactions without a price or a clear, unique geographic match (`mun_nhits != 1`) were removed to ensure the reliability of the analysis.
-   **Feature Engineering:** More useful features were extracted from the raw data, such as the day of the week from the `dateTime` column or the clean product category name from a URL string.

### 3.2. Implementation of Cleaning Pipeline

The following steps were implemented in a single, coherent `dplyr` pipeline for efficiency and reproducibility. The result is a cleaned DataFrame named `data_clean`.

```{r data-cleaning-pipeline}
#| label: data-cleaning-pipeline

# Comprehensive cleaning and transformation of the raw data
data_clean <- data %>%
  
  # Select and rename relevant columns for better readability
  rename(
    price = salesPrice.amountIncl,
    category_url = infos.Category,
    sales_rank_raw = infos.Sales_Rank,
    canton = mun_canton
  ) %>%
  select(
    price, dateTime, brandName, category_url, sales_rank_raw, canton, mun_nhits
  ) %>%
  
  # Filter rows to ensure data quality
  filter(
    !is.na(price),           # Keep only transactions with a price
    !is.na(canton),          # Keep only transactions with canton information
    mun_nhits == 1           # Keep only unique geographic matches
  ) %>%
  
  # Create new, useful columns (Feature Engineering)
  mutate(
    # Convert timestamp to a proper date-time format
    dateTime = ymd_hms(dateTime),
    
    # Extract useful time-based components
    hour = hour(dateTime),
    weekday = wday(dateTime, label = TRUE, week_start = 1),
    
    # Extract the product category from the URL
    category = basename(category_url)
  )
```

### 3.3. Exploratory Data Analysis (EDA)

After cleaning the data, an exploratory analysis was performed on the `data_clean` set to understand fundamental patterns before aggregation.

#### Price Distribution

An analysis of product prices reveals a heavily right-skewed distribution. A large majority of transactions are for lower-priced items, while a long tail of high-value purchases contributes significantly to total revenue. The boxplot identifies these high-priced items as statistical outliers. For a marketing analysis, however, these are valid and highly valuable data points that must be retained.

```{r eda-price-plots}
#| label: eda-price-plots

# Histogram to visualize the price distribution
ggplot(data_clean, aes(x = price)) +
  geom_histogram(bins = 100, fill = "steelblue", color = "black") +
  labs(
    title = "Distribution of Product Prices",
    subtitle = "Strong right-skewed distribution with most items in the lower price range",
    x = "Price (CHF)",
    y = "Number of Transactions"
  ) +
  theme_minimal()

# Boxplot to identify outliers
ggplot(data_clean, aes(y = price)) +
  geom_boxplot(fill = "steelblue") +
  labs(
    title = "Boxplot of Product Prices",
    subtitle = "Shows a high number of high-priced products (outliers)",
    y = "Price (CHF)"
  ) +
  theme_minimal()
```

#### Top Categories and Brands

Analyzing the most frequent categories and brands provides initial insights into customer preferences. Product categories such as headphones, smartphones, and printer toner dominate sales volumes. Among brands, Apple and Samsung are clear leaders, highlighting the importance of these ecosystems to customers.

```{r eda-category-brand-plots}
#| label: eda-category-brand-plots

# Top 15 product categories by transaction count
data_clean %>%
  count(category, sort = TRUE) %>%
  top_n(15, n) %>%
  ggplot(aes(x = reorder(category, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Top 15 Product Categories",
    x = "Product Category",
    y = "Number of Transactions"
  ) +
  theme_minimal()

# Top 15 brands by transaction count
data_clean %>%
  filter(brandName != "") %>% # Exclude blank brand names
  count(brandName, sort = TRUE) %>%
  top_n(15, n) %>%
  ggplot(aes(x = reorder(brandName, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Top 15 Brands",
    x = "Brand",
    y = "Number of Transactions"
  ) +
  theme_minimal()
```

### 3.4. Validation and Final Aggregation

An initial aggregation of the cleaned data surprisingly resulted in 29 groups instead of the 26 expected Swiss cantons. An investigation of the `canton` column revealed that the dataset also contained transactions from neighboring countries, which needed to be excluded for this analysis.

```{r validation-step}
#| label: validation-step

# A list of valid Swiss canton abbreviations
valid_swiss_cantons <- c(
  "AG", "AI", "AR", "BE", "BL", "BS", "FR", "GE", "GL", "GR", 
  "JU", "LU", "NE", "NW", "OW", "SG", "SH", "SO", "SZ", "TG", 
  "TI", "UR", "VD", "VS", "ZG", "ZH"
)

# Identify which unique codes in our data are NOT in the valid list
non_swiss_codes <- setdiff(unique(data_clean$canton), valid_swiss_cantons)

print("Found the following non-Swiss location codes:")
print(non_swiss_codes)
```

Based on this finding, the dataset was filtered to include only transactions from the 26 Swiss cantons. Afterward, the final aggregation was performed to create the analysis-ready dataset.

```{r final-aggregation}
#| label: final-aggregation

# Filter the dataset to retain only transactions from Swiss cantons
data_final_swiss <- data_clean %>%
  filter(canton %in% valid_swiss_cantons)

# Perform the final aggregation at the cantonal level
canton_data_final <- data_final_swiss %>%
  group_by(canton) %>%
  summarise(
    total_sales = sum(price, na.rm = TRUE),
    num_transactions = n(),
    avg_order_value = mean(price, na.rm = TRUE),
    top_brand = names(which.max(table(brandName))),
    top_category = names(which.max(table(category)))
  ) %>%
  arrange(desc(total_sales))
```

### 3.5. Final Aggregated Dataset

The result of this cleaning and preprocessing workflow is the `canton_data_final` DataFrame. It contains 26 rows, one for each Swiss canton, with the key performance indicators required for further analysis. This dataset is now ready to be merged with the BFS population data.

```{r display-final-table}
#| label: display-final-table
#| echo: false

# Display the final, clean table
print(canton_data_final, n = 26)
```
